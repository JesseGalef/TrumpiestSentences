{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Jesse Galef\n",
    "# July 2016\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Personid:\n",
    "# 20967 - Trump\n",
    "# 19027 - Clinton\n",
    "# 994 - Sanders\n",
    "# 4776 - jeb bush\n",
    "# 47822 - ben carson\n",
    "# 1007174 - chris christie\n",
    "# 1019953 - ted cruz\n",
    "# 1620 - john kasich\n",
    "# 24776 - huckabee\n",
    "# 9265241 - rand paul\n",
    "# 87599 - marco rubio\n",
    "\n",
    "# seriesid[]=91 for C-SPAN's \"Campaign 2016\" tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_person(name, name_yes, name_no):\n",
    "    # name is a string, name_yes and name_no are lists of strings\n",
    "    # if any of the 'name_yes' strings and none of the name_no strings appear in name, return True. Else False\n",
    "    return any([yes.lower() in name.lower() for yes in name_yes]) and not any([no.lower() in name.lower() for no in name_no])\n",
    "\n",
    "def id_to_df(person_id, person_name, name_yes, name_no):\n",
    "    # passed a person_id, name you're looking for, and name_yes/name_no (see above)\n",
    "    # returns a dataframe of transcripts scraped from C-SPAN's Campaign 2016-tagged videos\n",
    "    # Compiles the date of the transcript, title, a list of names of all people who talked in the transcript, and the url\n",
    "    \n",
    "    url = 'http://www.c-span.org/search/?sdate=01/01/2015&edate=12/31/2016&searchtype=Videos&sort=Most+Recent+Airing&text=1&seriesid[]=91&personid[]='\n",
    "    url = url + str(person_id)\n",
    "    url = url + '&show100=&sdate=01/01/2015&edate=12/31/2016&searchtype=Videos&sort=Most+Recent+Airing&text=0&seriesid[]=91&personid[]='\n",
    "    url = url + str(person_id)\n",
    "    url = url + '&ajax&page='\n",
    "\n",
    "    addon_url = \"&action=getTranscript&transcriptType=cc&\"\n",
    "\n",
    "    video_page = BeautifulSoup(urllib.urlopen(url).read(), 'lxml')\n",
    "    video_list = video_page.find_all('li', class_='onevid')\n",
    "    \n",
    "    # While there are more videos to load, add the li tags from the next page\n",
    "    page = 1\n",
    "    while video_page.find(id='loadmore') != None:\n",
    "        page += 1\n",
    "        more_url = url + str(page)\n",
    "        video_page = BeautifulSoup(urllib.urlopen(more_url).read(), 'lxml')\n",
    "        video_list = video_list + video_page.find_all('li', class_='onevid')\n",
    "    \n",
    "    info = [] # list of dicts that will be compiled into a dataframe\n",
    "\n",
    "    for video in video_list:    \n",
    "        date = video.find('time')['datetime']\n",
    "        link = video.find('a', class_='title')['href']\n",
    "\n",
    "        if link[:2] == '//':\n",
    "            link = 'http:' + link # Recently C-SPAN's links lost the 'http:', becoming '//www.' etc. I assume a glitch?\n",
    "\n",
    "        title = video.find('h3').text\n",
    "    \n",
    "        full_text = \"\"\n",
    "        names = [] # names of all people who talked in the transcript\n",
    "#         print str(link)+str(addon_url)\n",
    "        transcript_page = BeautifulSoup(urllib.urlopen(link+addon_url).read(), 'lxml')\n",
    "        rows = transcript_page.find_all('tr')\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            for cell in cells:\n",
    "                name = cell.find('strong')\n",
    "                if name != None: # this cell has an identified speaker\n",
    "                    names.append(name.text.lower())\n",
    "                    \n",
    "                    if is_person(name.text, name_yes, name_no):\n",
    "                        text_cell = cell.find('p', class_='short_transcript')\n",
    "                        if text_cell != None: # There's the occasional empty cell even with a speaker\n",
    "                            text = text_cell.text\n",
    "                            colon_pos = text[0:40].find(':')\n",
    "                            if colon_pos != -1:\n",
    "                                # Found a colon in the first 40 characters of this block, remove the name\n",
    "                                text = text[colon_pos+1:]\n",
    "                            if cell.find('span', class_='hidden-full-transcript-ellipses') != None:\n",
    "                                text = text[:-3] # remove ellipses\n",
    "                            text = re.sub('(\\[[^\\]]*\\])', '', text) # remove things like [applause] and [cheers]\n",
    "                            text = re.sub('(\\([^\\)]*\\))', '', text) # remove things like (music)\n",
    "                                                                    # Although unfortunately doesn't remove the lyrics themselves...\n",
    "                            text = text.replace('\\n',' ')\n",
    "                            full_text = full_text + \" \" + text     \n",
    "        info.append(\n",
    "        {'title': title,\n",
    "         'link': link,\n",
    "         'date': date,\n",
    "         'names': names,\n",
    "         'text': full_text,\n",
    "         'speaker': person_name\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(info)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates = [\n",
    "    {'pid':19027,'name':'Clinton','name_yes':['hillary','clinton'],'name_no':['bill','william','chelsea']},\n",
    "    {'pid':20967,'name':'Trump','name_yes':['donald','trump'],'name_no':['eric','melania','ivanka','jr']},\n",
    "#     {'pid':994,'name':'Sanders','name_yes':['bernie','bernard','sanders'],'name_no':['jane','levi']},\n",
    "#     {'pid':4776,'name':'Bush','name_yes':['jeb','bush'],'name_no':['george','barbara']},\n",
    "#     {'pid':47822,'name':'Carson','name_yes':['ben','carson'],'name_no':['candy','jr']},\n",
    "#     {'pid':1007174,'name':'Christie','name_yes':['chris','christie'],'name_no':['patrick','andrew','sarah','bridget']},\n",
    "#     {'pid':1019953,'name':'Cruz','name_yes':['ted','cruz'],'name_no':['heidi','rafael']},\n",
    "#     {'pid':1620,'name':'Kasich','name_yes':['kasich'],'name_no':['karen','emma','reese']},\n",
    "#     {'pid':87599,'name':'Rubio','name_yes':['marco','rubio'],'name_no':['jeanette']},\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinton 123.131715059\n",
      "Trump 142.968055964\n",
      "CPU times: user 18.7 s, sys: 1.6 s, total: 20.3 s\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "cand_df = {}\n",
    "for candidate in candidates:\n",
    "    cand_df[candidate['name']] = id_to_df(candidate['pid'], candidate['name'], candidate['name_yes'], candidate['name_no'])\n",
    "    cand_df[candidate['name']] = cand_df[candidate['name']][cand_df[candidate['name']].text != '']\n",
    "    print candidate['name'], time.time()-t0\n",
    "    t0=time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cand in cand_df:\n",
    "    cand_df[cand].to_csv(cand+\"_transcript_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
